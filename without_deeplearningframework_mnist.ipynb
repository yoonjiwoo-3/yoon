{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import os\n",
        "\n",
        "# 다운로드할 MNIST 데이터셋 URL과 MD5 해시값\n",
        "urls = [\n",
        "    ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
        "    ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz', 'd53e105ee54ea40749a09fcbcd1e9432'),\n",
        "    ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz', '9fb629c4189551a2d022fa330f9573f3'),\n",
        "    ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz', 'ec29112dd5afa0611ce80d1b7f02629c')\n",
        "]\n",
        "\n",
        "# 파일 다운로드 함수\n",
        "def download_and_verify(url, md5_hash):\n",
        "    filename = url.split(\"/\")[-1]\n",
        "    # 파일 다운로드\n",
        "    os.system(f\"wget {url}\")\n",
        "\n",
        "    # 다운로드된 파일의 MD5 해시값 확인\n",
        "    downloaded_md5 = hashlib.md5(open(filename, 'rb').read()).hexdigest()\n",
        "\n",
        "    # MD5 해시값 검증\n",
        "    if downloaded_md5 == md5_hash:\n",
        "        print(f\"{filename} 다운로드 성공! 해시값이 일치합니다.\")\n",
        "    else:\n",
        "        print(f\"{filename} 다운로드 실패! 해시값이 일치하지 않습니다.\")\n",
        "\n",
        "# 각 파일에 대해 다운로드 및 해시값 검증\n",
        "for url, md5 in urls:\n",
        "    download_and_verify(url, md5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbF5HftRRbhZ",
        "outputId": "173a3fd5-e09a-4310-8920-15fe56c41b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train-images-idx3-ubyte.gz 다운로드 성공! 해시값이 일치합니다.\n",
            "train-labels-idx1-ubyte.gz 다운로드 성공! 해시값이 일치합니다.\n",
            "t10k-images-idx3-ubyte.gz 다운로드 성공! 해시값이 일치합니다.\n",
            "t10k-labels-idx1-ubyte.gz 다운로드 성공! 해시값이 일치합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gzip\n",
        "import struct\n",
        "\n",
        "# 파일 압축 해제 함수\n",
        "def extract_gz(filename):\n",
        "    with gzip.open(filename, 'rb') as f_in:\n",
        "        with open(filename[:-3], 'wb') as f_out:\n",
        "            f_out.write(f_in.read())\n",
        "\n",
        "# idx 파일 읽기 함수\n",
        "def read_idx(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        magic_number = struct.unpack('>I', f.read(4))[0]\n",
        "        if magic_number == 2051:  # 이미지 파일\n",
        "            num_images = struct.unpack('>I', f.read(4))[0]\n",
        "            rows = struct.unpack('>I', f.read(4))[0]\n",
        "            cols = struct.unpack('>I', f.read(4))[0]\n",
        "            images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_images, rows, cols)\n",
        "            return images\n",
        "        elif magic_number == 2049:  # 레이블 파일\n",
        "            num_labels = struct.unpack('>I', f.read(4))[0]\n",
        "            labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "            return labels\n",
        "\n",
        "# MNIST 데이터 로드\n",
        "train_images_path = 'train-images-idx3-ubyte.gz'\n",
        "train_labels_path = 'train-labels-idx1-ubyte.gz'\n",
        "test_images_path = 't10k-images-idx3-ubyte.gz'\n",
        "test_labels_path = 't10k-labels-idx1-ubyte.gz'\n",
        "\n",
        "extract_gz(train_images_path)\n",
        "extract_gz(train_labels_path)\n",
        "extract_gz(test_images_path)\n",
        "extract_gz(test_labels_path)\n",
        "\n",
        "x_train = read_idx('train-images-idx3-ubyte') / 255.0\n",
        "y_train = read_idx('train-labels-idx1-ubyte')\n",
        "x_test = read_idx('t10k-images-idx3-ubyte') / 255.0\n",
        "y_test = read_idx('t10k-labels-idx1-ubyte')\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# 합성곱 연산\n",
        "\n",
        "def conv2d(input, kernel):\n",
        "    input_h, input_w, input_c = input.shape\n",
        "    kernel_h, kernel_w, _, output_c = kernel.shape\n",
        "    output_h, output_w = input_h - kernel_h + 1, input_w - kernel_w + 1\n",
        "    output = np.zeros((output_h, output_w, output_c))\n",
        "\n",
        "    for h in range(output_h):\n",
        "        for w in range(output_w):\n",
        "            for c in range(output_c):\n",
        "                output[h, w, c] = np.sum(input[h:h+kernel_h, w:w+kernel_w, :] * kernel[:, :, :, c])\n",
        "    return output\n",
        "\n",
        "# 맥스 풀링\n",
        "\n",
        "def max_pooling(input, size=2):\n",
        "    input_h, input_w, input_c = input.shape\n",
        "    output_h, output_w = input_h // size, input_w // size\n",
        "    output = np.zeros((output_h, output_w, input_c))\n",
        "\n",
        "    for h in range(output_h):\n",
        "        for w in range(output_w):\n",
        "            for c in range(input_c):\n",
        "                output[h, w, c] = np.max(input[h*size:(h+1)*size, w*size:(w+1)*size, c])\n",
        "    return output\n",
        "\n",
        "# 활성화 함수 및 손실 함수\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "def cross_entropy_loss(y_pred, y_true):\n",
        "    y_one_hot = np.eye(10)[y_true]\n",
        "    return -np.sum(y_one_hot * np.log(y_pred + 1e-9)) / len(y_true)\n",
        "\n",
        "# 가중치 업데이트\n",
        "\n",
        "def update_weights(W, b, dW, db, lr=0.01):\n",
        "    W -= lr * dW\n",
        "    b -= lr * db.squeeze()  # 차원 맞추기\n",
        "    return W, b\n",
        "\n",
        "# 학습 함수\n",
        "\n",
        "def train_cnn(x_train, y_train, x_test, y_test, epochs=5, lr=0.01):\n",
        "    kernel = np.random.randn(3, 3, 1, 2) * np.sqrt(2 / (3 * 3 * 1))\n",
        "    flattened_size = ((28 - 3 + 1) // 2) ** 2 * 2\n",
        "    W = np.random.randn(flattened_size, 10) * np.sqrt(2 / flattened_size)\n",
        "    b = np.zeros(10)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss, correct = 0, 0\n",
        "        for i in range(len(x_train)):\n",
        "            img, label = x_train[i], y_train[i]\n",
        "            conv_out = relu(conv2d(img, kernel))\n",
        "            pooled_out = max_pooling(conv_out)\n",
        "            flattened = pooled_out.flatten()\n",
        "            logits = np.dot(flattened, W) + b\n",
        "            y_pred = softmax(logits.reshape(1, -1))\n",
        "            loss += cross_entropy_loss(y_pred, np.array([label]))\n",
        "\n",
        "            if np.argmax(y_pred) == label:\n",
        "                correct += 1\n",
        "\n",
        "            y_one_hot = np.eye(10)[label]\n",
        "            dL_dlogits = y_pred - y_one_hot\n",
        "            dW = np.outer(flattened, dL_dlogits)\n",
        "            db = dL_dlogits\n",
        "            W, b = update_weights(W, b, dW, db, lr)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Accuracy={(correct / len(x_train)) * 100:.2f}%\")\n",
        "\n",
        "    # 테스트 평가\n",
        "    correct = 0\n",
        "    for i in range(len(x_test)):\n",
        "        img, label = x_test[i], y_test[i]\n",
        "        conv_out = relu(conv2d(img, kernel))\n",
        "        pooled_out = max_pooling(conv_out)\n",
        "        flattened = pooled_out.flatten()\n",
        "        logits = np.dot(flattened, W) + b\n",
        "        y_pred = softmax(logits.reshape(1, -1))\n",
        "\n",
        "        if np.argmax(y_pred) == label:\n",
        "            correct += 1\n",
        "\n",
        "    print(f\"Test Accuracy: {(correct / len(x_test)) * 100:.2f}%\")\n",
        "\n",
        "train_cnn(x_train, y_train, x_test, y_test, epochs=5, lr=0.01)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wU-iotGrEZf",
        "outputId": "e80afecb-fd0d-4b3f-9e53-687bd2579f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss=19928.0321, Accuracy=90.31%\n",
            "Epoch 2: Loss=15293.5647, Accuracy=92.46%\n",
            "Epoch 3: Loss=14107.4863, Accuracy=93.06%\n",
            "Epoch 4: Loss=13411.8178, Accuracy=93.38%\n",
            "Epoch 5: Loss=12937.7804, Accuracy=93.61%\n",
            "Test Accuracy: 93.04%\n"
          ]
        }
      ]
    }
  ]
}